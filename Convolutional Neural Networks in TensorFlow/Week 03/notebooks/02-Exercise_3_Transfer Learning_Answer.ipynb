{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d5e5a536-6084-4c1f-a9f7-a076c97c01d8"
      },
      "cell_type": "code",
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-29 19:43:59--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 2607:f8b0:4001:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  60.3MB/s    in 1.4s    \n",
            "\n",
            "2019-04-29 19:44:00 (60.3 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TzPHPSEKgLZV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11376
        },
        "outputId": "1653ef78-c8bf-42cc-f3d5-e09bb6ff48d2"
      },
      "cell_type": "code",
      "source": [
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "    # Your Code Here\n",
        "    layer.trainable = False\n",
        "\n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3f9ab42-fa78-4550-80d9-5fda1b2d61cc"
      },
      "cell_type": "code",
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7') # Your Code Here\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output # Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8520
        },
        "outputId": "40ec5d11-d682-44a7-d8e3-7635aa9cc379"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', # Your Code Here\n",
        "              metrics = ['accuracy']) # Your Code Here\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "100f280c-9bc0-4f05-d582-a18c40c02c85"
      },
      "cell_type": "code",
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-29 19:44:35--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 2607:f8b0:4001:c0d::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   133MB/s    in 1.1s    \n",
            "\n",
            "2019-04-29 19:44:36 (133 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-04-29 19:44:38--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 2607:f8b0:4001:c20::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-04-29 19:44:38 (115 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8vgWReAngEQt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "bf3f47e2-d5c6-48cd-d10f-a6ecc91794e5"
      },
      "cell_type": "code",
      "source": [
        "train_horses_dir = \"/tmp/training/horses\" # Your Code Here\n",
        "train_humans_dir = \"/tmp/training/humans\" # Your Code Here\n",
        "validation_horses_dir = \"/tmp/validation/horses\" # Your Code Here\n",
        "validation_humans_dir = \"/tmp/validation/humans\" # Your Code Here\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir) # Your Code Here\n",
        "train_humans_fnames = os.listdir(train_humans_dir) # Your Code Here\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir) # Your Code Here\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir) # Your Code Here\n",
        "\n",
        "print(len(train_horses_fnames)) # Your Code Here\n",
        "print(len(train_humans_fnames)) # Your Code Here\n",
        "print(len(validation_horses_fnames)) # Your Code Here\n",
        "print(len(validation_humans_fnames)) # Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9e60f9ae-71a7-4dc4-f3f2-4ee5ee2f53db"
      },
      "cell_type": "code",
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                         batch_size = 20,\n",
        "                                                         class_mode = 'binary',\n",
        "                                                         target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('acc')>0.999):\n",
        "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1907
        },
        "outputId": "22111b0c-8671-45ca-9c22-3162111479ad"
      },
      "cell_type": "code",
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(train_generator,\n",
        "                              validation_data=validation_generator,\n",
        "                              epochs=100,\n",
        "                              verbose=1,\n",
        "                              callbacks=[callbacks])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 5.2814e-04 - acc: 1.0000\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0803 - acc: 0.9776 - val_loss: 5.2814e-04 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 1.3987e-04 - acc: 1.0000\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0628 - acc: 0.9757 - val_loss: 1.3987e-04 - val_acc: 1.0000\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 1.8598e-04 - acc: 1.0000\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0489 - acc: 0.9815 - val_loss: 1.8598e-04 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.0078 - acc: 0.9922\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 0.0846 - acc: 0.9727 - val_loss: 0.0078 - val_acc: 0.9922\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 2s 127ms/step - loss: 0.0422 - acc: 0.9844\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0541 - acc: 0.9786 - val_loss: 0.0422 - val_acc: 0.9844\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 1s 111ms/step - loss: 0.0153 - acc: 0.9961\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0423 - acc: 0.9883 - val_loss: 0.0153 - val_acc: 0.9961\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.0097 - acc: 0.9961\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0235 - acc: 0.9903 - val_loss: 0.0097 - val_acc: 0.9961\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 1s 106ms/step - loss: 0.0330 - acc: 0.9922\n",
            "52/52 [==============================] - 12s 223ms/step - loss: 0.0498 - acc: 0.9766 - val_loss: 0.0330 - val_acc: 0.9922\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.0498 - acc: 0.9922\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0256 - acc: 0.9903 - val_loss: 0.0498 - val_acc: 0.9922\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.0290 - acc: 0.9961\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0342 - acc: 0.9922 - val_loss: 0.0290 - val_acc: 0.9961\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.0296 - acc: 0.9922\n",
            "52/52 [==============================] - 12s 223ms/step - loss: 0.0244 - acc: 0.9932 - val_loss: 0.0296 - val_acc: 0.9922\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 2s 129ms/step - loss: 0.0551 - acc: 0.9883\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 0.0569 - acc: 0.9873 - val_loss: 0.0551 - val_acc: 0.9883\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.0363 - acc: 0.9961\n",
            "52/52 [==============================] - 12s 230ms/step - loss: 0.0425 - acc: 0.9912 - val_loss: 0.0363 - val_acc: 0.9961\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.0342 - acc: 0.9961\n",
            "52/52 [==============================] - 12s 223ms/step - loss: 0.0425 - acc: 0.9873 - val_loss: 0.0342 - val_acc: 0.9961\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 1s 113ms/step - loss: 0.0470 - acc: 0.9922\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0169 - acc: 0.9942 - val_loss: 0.0470 - val_acc: 0.9922\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.0305 - acc: 0.9961\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0412 - acc: 0.9883 - val_loss: 0.0305 - val_acc: 0.9961\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.0517 - acc: 0.9922\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0130 - acc: 0.9961 - val_loss: 0.0517 - val_acc: 0.9922\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.0458 - acc: 0.9961\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 0.0321 - acc: 0.9912 - val_loss: 0.0458 - val_acc: 0.9961\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 1s 114ms/step - loss: 0.0427 - acc: 0.9961\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0213 - acc: 0.9922 - val_loss: 0.0427 - val_acc: 0.9961\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.1533 - acc: 0.9688\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0401 - acc: 0.9922 - val_loss: 0.1533 - val_acc: 0.9688\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.1972 - acc: 0.9648\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0219 - acc: 0.9932 - val_loss: 0.1972 - val_acc: 0.9648\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.1725 - acc: 0.9688\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0437 - acc: 0.9883 - val_loss: 0.1725 - val_acc: 0.9688\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.0967 - acc: 0.9922\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0336 - acc: 0.9912 - val_loss: 0.0967 - val_acc: 0.9922\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.4322 - acc: 0.9531\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 0.0069 - acc: 0.9981 - val_loss: 0.4322 - val_acc: 0.9531\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 2s 129ms/step - loss: 0.6523 - acc: 0.9453\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0103 - acc: 0.9942 - val_loss: 0.6523 - val_acc: 0.9453\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.0643 - acc: 0.9922\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 0.0355 - acc: 0.9912 - val_loss: 0.0643 - val_acc: 0.9922\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.1534 - acc: 0.9766\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0172 - acc: 0.9942 - val_loss: 0.1534 - val_acc: 0.9766\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.2931 - acc: 0.9531\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0086 - acc: 0.9942 - val_loss: 0.2931 - val_acc: 0.9531\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.1387 - acc: 0.9844\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0377 - acc: 0.9971 - val_loss: 0.1387 - val_acc: 0.9844\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.0914 - acc: 0.9922\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 0.0339 - acc: 0.9942 - val_loss: 0.0914 - val_acc: 0.9922\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 1s 111ms/step - loss: 0.1626 - acc: 0.9805\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0229 - acc: 0.9932 - val_loss: 0.1626 - val_acc: 0.9805\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 2s 126ms/step - loss: 0.5356 - acc: 0.9531\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0106 - acc: 0.9981 - val_loss: 0.5356 - val_acc: 0.9531\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.1067 - acc: 0.9922\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0137 - acc: 0.9971 - val_loss: 0.1067 - val_acc: 0.9922\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 0.1421 - acc: 0.9883\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0085 - acc: 0.9971 - val_loss: 0.1421 - val_acc: 0.9883\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.3764 - acc: 0.9531\n",
            "52/52 [==============================] - 12s 223ms/step - loss: 0.0446 - acc: 0.9912 - val_loss: 0.3764 - val_acc: 0.9531\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.4369 - acc: 0.9531\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0061 - acc: 0.9990 - val_loss: 0.4369 - val_acc: 0.9531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "d052ccc8-e1f4-4d07-bf60-3bc11ffefde7"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nroN403fOuQ7iTd855zrIP8mCqx4g2/wkAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "kSxoK_wtsbvI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}